%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Template: Praxisprojekt WS 2017
%
% Date: October 2017
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}
\usepackage[a4paper]{geometry}
\usepackage{framed}
\usepackage[myheadings]{fullpage}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{graphicx, wrapfig, subcaption, setspace, booktabs}
\usepackage[T1]{fontenc}
\usepackage[font=small, labelfont=bf]{caption}
\usepackage[protrusion=true, expansion=true]{microtype}
\usepackage[german]{babel}
\usepackage{sectsty}
\usepackage{url, lipsum}
\usepackage[parfill]{parskip}
\usepackage{hyperref}

%-------------------------------------------------------------------------------
% Commands
%-------------------------------------------------------------------------------
\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
\input{env}
%-------------------------------------------------------------------------------
% HEADER & FOOTER
%-------------------------------------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\setlength\headheight{15pt}
\fancyhead[L]{\newCommandName}
\fancyhead[R]{\newCommandUniversity}
\fancyfoot[R]{Seite \thepage\ von \pageref{LastPage}}

%-------------------------------------------------------------------------------
% TITLE PAGE
%-------------------------------------------------------------------------------
\begin{document}


\title{ \normalsize
		\HRule{0.5pt} \\
		\LARGE \textbf{\uppercase{\newCommandDiscipline}} \\
    \smallbreak
		\small\textbf{{\newCommandTerm}}\\
		\HRule{2pt} \\ [0.5cm]
		\normalsize \today \vspace*{10\baselineskip}}

\date{}

\author{
		\newCommandName \\
		\newCommandMatriculationNumber \\
		\newCommandUniversity \\
		\newCommandFaculty
}

\pagenumbering{gobble}

\maketitle

\newpage

\pagenumbering{arabic}


%-------------------------------------------------------------------------------
% Section title formatting
\sectionfont{\scshape}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
% BODY
%-------------------------------------------------------------------------------

\section{Entwicklung einer REST-API f"ur HPC Jobs}
Cloud Computing erm"oglicht die flexible Nutzung von Computing Resources.

Durch den Einsatz von HTTP und JSON basierten Schnittstellen (REST-API's) wird es f"ur Kunden m"oglich, sehr flexibel (z.B. automatisiert) Computing Resources zu nutzen.

M"ogliche Anwendungsf"alle sind sehr vielf"altig. So kann man z.B. in einer Continous Integration Pipeline diese API nutzen. Auf diese Weise k"onnen CAE-Modelle bei jeder "Anderung durchgerechnet werden, und getestet werden, ob sie alle Anforderungen erf"ullen.

Auch die M"oglichkeit, die API in HPC Software einzubauen, die sonst auf Workstations arbeitet und anschliessend transparent Computing Resources in der Cloud nutzen kann, ist interessant. Insbesondere bei Variantensimulationen, also Simulationen, bei denen einige Parameter des Modells variiert werden, ist so eine Funktionalit"at n"utzlich. Normalerweise nutzen Ingenieure selten Variantensimulationen, da diese auf den Workstations zu aufw"andig sind.



\subsection{Beschreibung}


Die API soll vor allem Serverseitig umgesetzt werden. Clientseitig sollen mindestens automatisierte Integrationtests umgesetzt werden.

Der Transport/Kodierung der Daten erfolgt mittels HTTP und JSON. Die Daten sollen Transport-verschl"usselt (TLS) "ubertragen werden. Berechtigungen sollen von der API anhand geheimer Tokens gepr"uft werden.

Die API soll folgende Funktionalit"aten beinhalten:

\begin{itemize}
\item Authentifizierung / Autorisierung mittels Tokens
\item Upload der Inputfiles / Download der Outputfiles
\item Anlegen eines Jobs mittels Job Templates und Verifikation der Meta-Daten
\item "Ubergabe des Jobs an eine Queueing Engine, Abfrage des aktuellen Status und der Historie
\item Der Job soll bei der Ausf"uhrung Zugriff auf die Inputdaten bekommen und die Outputdaten anschliessend wieder in den Object-Store schreiben.
\item Ergebnisse und Metadaten bzw. Ausgabe und Fehlermeldungen des Jobs werden zum Download angeboten
\item Insbesondere soll es m"oglich sein, dass ein Job "uber die beschriebene API neue Jobs in die Queue einstellen kann. Dadurch soll der Upload von Variantensimulationen wesentlich vereinfacht und beschleunigt werden.
\end{itemize}

Es soll sp"ater viele Arten von Jobs geben und die Jobs sollen spezielle Anforderungen an die Laufzeit-Umgebung haben k"onnen (z.B. Anzahl Server und Cores pro Server). Dies soll in der Entwicklung der REST API ber"ucksichtigt werden. So soll es m"oglich sein, sich eine Liste aller m"oglichen Job-Templates und Laufzeit-Umgebungen ausgeben zu lassen.

Zugriff auf Ausgabe und Fehlermeldungen zur Laufzeit des Jobs (nicht erst nachdem er beendet ist) w"are w"unschenswert, ist aber nicht zwingend notwendig.

\subsection{Umsetzung}


Die API selbst soll auf existierender Software basieren. Eine Anlehnung an existierende API's ist ausdr"ucklich gew"unscht, aber nicht zwingend erforderlich.

Vermutlich ist es am sinnvollsten, einen Reverse-Proxy vor die gesamte REST-Architektur zu schalten. Dadurch kann Authentifizierung und Authorisierung an einer Stelle erm"oglicht werden.

Job-Templates sollen dabei aus Docker Containern und Adaptern zur Verifikation und "ubergabe der Input bzw. Output-Daten bestehen.

Als Queueing System kann die Univa Grid-Engine oder eine der vielen Open Source Alternativen zum Einsatz kommen.

Der Object-Storage soll kompatibel zu AWS S3 sein. RedHat Ceph oder Minio bieten sich hier an.

Ausserdem wird vermutlich eine Datenbank ben"otigt, welche die Informationen aus den einzelnen Komponenten verkn"upft. Zum aktuellen Zeitpunkt ist unklar, welche Art von Datenbank daf"ur am geeignetsten ist: relational, dokumentenorientiert oder Key-Value Store, verteilt oder nicht.

\subsection{Vorgehensweise}

In iterativen Entwicklungszyklen von ca 2 Wochen sollen zuerst ein oder zwei Prototypen der REST Schnittstelle erstellt werden. Dies dient dazu, die geeignete Programmiersprache und vielleicht ein Framework zu finden.

Die verschiedenen Routes in der API werden per Mockup angelegt, bzw. dokumentiert. M"oglicherweise bestehen einige Routen auch nur aus einem Proxy zum Object-Store.

Nebenl"aufig testen wir den Zugriff auf die Komponenten des Software Systems und "uberlegen, welche Anforderungen an die Datenbank-Modelle gestellt werden. Anschliessend soll die Integration gebaut werden, so dass f"ur ein Beispiel-Jobtemplate der komplette Durchlauf funktioniert.

Test Driven Development (TDD) ist ausdr"ucklich erw"unscht.
\newpage

\section{Zus"atzliche Informationen}
\subsection{Unternehmen}

CPU 24/7 ist spezialisiert auf die Vermietung und Administration
von High Performance Computing (HPC) Clustern.
Unsere Kunden sind Ingenieure, Maschinenbauer, Schiffsbauer und Autozulieferer.
Diese nutzen unsere Cluster um ihre 3D-Modelle in Physiksimulationen (Computer Aided Engineering, CAE)
zu optimieren und auf diese Weise die Entwicklungszeit von neuen Produkten zu reduzieren.



\subsection{Ansprechpersonen}

% \subsubsection{fachlich:}
% \texttt
\textbf{Richard Metzler M.Sc.}\\
Software Engineer Software Development

CPU 24/7 GmbH \\
August-Bebel-Stra"se 26-53\\
DE 14482 Potsdam

Telefon: +49 (0) 331 279 784 51 \\
E-Mail: r.metzler@cpu-24-7.com

% \subsubsection{organisatorisch:}
% \texttt
\textbf{Jenny Dawon M.A.}\\
Chief Administrative Officer (CAO)

CPU 24/7 GmbH\\
August-Bebel-Stra"se 26-53\\
DE 14482 Potsdam

Tel.: +49 (0) 331 279 784 44\\
E-Mail: j.dawon@cpu-24-7.com

\subsection{Ressourcen}
\textbf{Git-Repository als Versionskontrolle:}\\
\url{https://github.com/MatthiasHertel/ws17_pp}

\textbf{Webseite zur Dokumentation:}\\
\url{https://www.ws17-pp.mhertel.de}

\end{document}
